#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-8, %rdx
	jge Loop

JmpTable:
	addq %rdx, %rdx
	addq %rdx, %rdx
	addq %rdx, %rdx
	mrmovq Table(%rdx), %rdx
	pushq %rdx
	ret

	.quad $0x31
    .quad Re1
    .quad Re2
    .quad Re3
    .quad Re4
    .quad Re5
    .quad Re6
    .quad Re7
Table:

Loop:	
	mrmovq (%rdi), %rcx
	mrmovq 8(%rdi), %r8
	mrmovq 16(%rdi), %r9
	mrmovq 24(%rdi), %r10
	mrmovq 32(%rdi), %r11
	mrmovq 40(%rdi), %r12
	mrmovq 48(%rdi), %r13
	mrmovq 56(%rdi), %r14

L12:
	rmmovq %r8, 8(%rsi)
    xorq %rcx, %r8
    rmmovq %rcx, (%rsi)

    jge L12same
    iaddq $1, %rax
	jmp L34
L12same:
	andq %rcx, %rcx
	jle L34
	iaddq $2, %rax

L34:
	rmmovq %r10, 24(%rsi)
    xorq %r9, %r10
    rmmovq %r9, 16(%rsi)

    jge L34same
    iaddq $1, %rax
	jmp L56
L34same:
	andq %r9, %r9
	jle L56
	iaddq $2, %rax

L56:
	rmmovq %r12, 40(%rsi)
    xorq %r11, %r12
    rmmovq %r11, 32(%rsi)

    jge L56same
    iaddq $1, %rax
	jmp L78
L56same:
	andq %r11, %r11
	jle L78
	iaddq $2, %rax

L78:
    rmmovq %r14, 56(%rsi)
    xorq %r13, %r14
    rmmovq %r13, 48(%rsi)

    jge L78same
    iaddq $1, %rax
	jmp Lfinal
L78same:
	andq %r13, %r13
	jle Lfinal
	iaddq $2, %rax

Lfinal:
	iaddq $64, %rdi
	iaddq $64, %rsi
    iaddq $-8, %rdx
    jge Loop
    jmp JmpTable

Re7:
    mrmovq 48(%rdi), %r8
	mrmovq 40(%rdi), %r9
    rmmovq %r8, 48(%rsi)
    andq %r8, %r8
    jle Re6p
    iaddq $1, %rax

Re6:
	mrmovq 40(%rdi), %r9
Re6p:
    mrmovq 32(%rdi), %r10
    rmmovq %r9, 40(%rsi)
    andq %r9, %r9
    jle Re5p
    iaddq $1, %rax

Re5:
	mrmovq 32(%rdi), %r10
Re5p:
    mrmovq 24(%rdi), %r11
    rmmovq %r10, 32(%rsi)
    andq %r10, %r10
    jle Re4p
    iaddq $1, %rax

Re4:
	mrmovq 24(%rdi), %r11
Re4p:
    mrmovq 16(%rdi), %r12
    rmmovq %r11, 24(%rsi)
    andq %r11, %r11
    jle Re3p
    iaddq $1, %rax
	
Re3:
	mrmovq 16(%rdi), %r12
Re3p:
    mrmovq 8(%rdi), %r13
    rmmovq %r12, 16(%rsi)
    andq %r12, %r12
    jle Re2p
    iaddq $1, %rax
	
Re2:
	mrmovq 8(%rdi), %r13
Re2p:
    mrmovq (%rdi), %r14
    rmmovq %r13, 8(%rsi)
    andq %r13, %r13
    jle Re1p
    iaddq $1, %rax

Re1:
	mrmovq (%rdi), %r14
Re1p:
    rmmovq %r14, (%rsi)
    andq %r14, %r14
    jle $0x31
    iaddq $1, %rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad -2
	.quad 3
	.quad 4
	.quad -5
	.quad -6
	.quad -7
	.quad 8
	.quad 9
	.quad -10
	.quad -11
	.quad 12
	.quad 13
	.quad -14
	.quad 15
	.quad 16
	.quad -17
	.quad -18
	.quad -19
	.quad 20
	.quad 21
	.quad -22
	.quad 23
	.quad -24
	.quad -25
	.quad -26
	.quad 27
	.quad 28
	.quad -29
	.quad -30
	.quad -31
	.quad 32
	.quad -33
	.quad 34
	.quad -35
	.quad -36
	.quad -37
	.quad 38
	.quad 39
	.quad -40
	.quad -41
	.quad 42
	.quad -43
	.quad -44
	.quad 45
	.quad 46
	.quad 47
	.quad -48
	.quad -49
	.quad -50
	.quad 51
	.quad -52
	.quad 53
	.quad 54
	.quad 55
	.quad 56
	.quad 57
	.quad 58
	.quad 59
	.quad 60
	.quad -61
	.quad 62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
